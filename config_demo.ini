
[Cora]
epoch = 100
lr = 0.001
weight_decay = 0.1
dropout = 0.1
train_ratio = 0.48
valid_ratio = 0.32
hdim = 512
layers =  8
add_edge = 2
alpha = 0.8
sampling_rate = 0.2


[Citeseer]
epoch = 100
lr = 0.001
weight_decay = 5e-8
dropout = 0.1
train_ratio = 0.48
valid_ratio = 0.32
hdim = 512
layers = 8
add_edge = 2
sampling_rate = 0.2
alpha = 0.8


[Pubmed]
epoch = 100
lr = 0.001
weight_decay = 8e-2
dropout = 0.1
train_ratio = 0.48
valid_ratio = 0.32
hdim = 512
layers = 12
add_edge = 5
alpha = 0.5
sampling_rate = 0.2

[Penn94]
epoch = 500
lr = 0.001
weight_decay = 5e-8
dropout = 0.1
train_ratio = 0.48
valid_ratio = 0.32
hdim = 512
layers = 2
add_edge = 2
sampling_rate = 0.2
alpha = 0.8

[Texas]
epoch = 100
lr = 0.001
weight_decay = 5e-4
dropout = 0.7
train_ratio = 0.48
valid_ratio = 0.32
hdim = 512
layers = 8
add_edge = 5
alpha = 0.5
sampling_rate = 0.2

[Wisconsin]
epoch = 100
lr = 0.001
weight_decay = 5e-1
dropout = 0.5
train_ratio = 0.48
valid_ratio = 0.32
hdim = 512
layers = 8
add_edge = 5
alpha = 0.2

[Tolokers]
epoch = 500
lr = 0.001
weight_decay = 5e-8
dropout = 0.1
train_ratio = 0.48
valid_ratio = 0.32
hdim = 512
layers = 2
add_edge = 2
sampling_rate = 0.2
alpha = 0.8
